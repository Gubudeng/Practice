{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv('train.csv')\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.002015    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   29.699118    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "# Age样本少，要进行填充\n",
    "titanic['Age'] = titanic['Age'].fillna(titanic['Age'].mean())\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "# 打印Sex的种类\n",
    "print (titanic['Sex'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "titanic.loc[titanic['Sex'] == 'male', 'Sex'] = 0\n",
    "titanic.loc[titanic['Sex'] == 'female', 'Sex'] = 1\n",
    "print (titanic['Sex'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "print (titanic['Embarked'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Embarked'] = titanic['Embarked'].fillna('S')\n",
    "titanic.loc[titanic['Embarked'] == 'S', 'Embarked'] = 0\n",
    "titanic.loc[titanic['Embarked'] == 'C', 'Embarked'] = 1\n",
    "titanic.loc[titanic['Embarked'] == 'Q', 'Embarked'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(titanic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# import cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# The columus we'll use to predict the target\n",
    "predictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset. It return the row indices corresponding to train\n",
    "# We set random_state to ensure we get the same split every time we run this\n",
    "kf = KFold(n_splits=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf.split(titanic):\n",
    "    # The predictors we're using to train the algorithm. Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    train_target = titanic['Survived'].iloc[train]\n",
    "    # Training the algorithm using the predictors and target\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.09277887,  0.96268076,  0.59418598,  0.93147996,  0.0542683 ,\n",
      "        0.16669896,  0.36895288,  0.10781588,  0.52152644,  0.87905196,\n",
      "        0.65197938,  0.82770141,  0.1376113 , -0.1637553 ,  0.66083526,\n",
      "        0.63827393,  0.16006955,  0.28782981,  0.53654427,  0.61480103,\n",
      "        0.26299049,  0.26393325,  0.73817417,  0.50760735,  0.56443493,\n",
      "        0.33179707,  0.12484479,  0.46979815,  0.6564497 ,  0.08366634,\n",
      "        0.47958876,  1.03550243,  0.65640385,  0.08524764,  0.53215027,\n",
      "        0.40223995,  0.12484628,  0.1320551 ,  0.57533875,  0.67001779,\n",
      "        0.48351312,  0.76218581,  0.12508284,  0.87601236,  0.71589614,\n",
      "        0.08372106,  0.1357618 ,  0.65640385,  0.06310204,  0.6087039 ,\n",
      "        0.05320397,  0.13196638,  0.9034952 ,  0.75284781,  0.31872044,\n",
      "        0.49816671,  0.82523289,  0.13150882,  0.81857575, -0.03401834,\n",
      "        0.16762412,  0.95779377,  0.3967412 ,  0.06500459,  0.53682253,\n",
      "        0.06013413,  0.78078329,  0.14320593,  0.44220537,  0.03761921,\n",
      "        0.27415845,  0.4281569 ,  0.35763411,  0.1145272 ,  0.08812936,\n",
      "        0.10968835,  0.08366634,  0.08372106,  0.38566859,  0.57357589,\n",
      "        0.12683604,  0.08812007,  0.65641715,  0.51172396,  0.84745769,\n",
      "        0.45779663,  0.03337934,  0.08372106,  0.93752959,  0.1153865 ,\n",
      "        0.0876055 ,  0.13754181,  0.38327117,  0.00704094, -0.07936441,\n",
      "        0.08372106,  0.30980709,  0.55257026,  0.72331734,  0.23511056,\n",
      "        0.58306322,  0.08366634,  0.52720936,  0.06559512, -0.02376072,\n",
      "        0.09310698,  0.62186939,  0.08362347,  0.03754497,  0.62878776,\n",
      "        0.40789507,  0.66837974,  0.1264989 ,  0.59476133,  0.68792683,\n",
      "        0.13201074, -0.06025027,  0.26111716,  0.61236972,  0.53383483,\n",
      "        0.29076186,  0.08372106,  0.28630601,  0.76222379,  0.34385476,\n",
      "        0.19117395,  0.1664476 ,  0.11506416,  0.55261446, -0.0016752 ,\n",
      "        0.10674248,  0.13725642,  0.44640299,  0.75284781,  0.31393905,\n",
      "        0.36719397,  0.97605666,  0.43041131,  0.16025014,  0.58675692,\n",
      "        0.54940555,  0.61634868,  0.57467468,  0.22553916,  0.35230013,\n",
      "        0.28814758,  0.09862769,  0.56291381,  0.18641429,  0.21948365,\n",
      "        0.16930928,  1.00850145, -0.05963381, -0.04224373,  0.08345934,\n",
      "        0.39629432,  0.73251296,  0.0820493 ,  0.08393842, -0.23018472,\n",
      "       -0.02700167,  0.72152821,  0.10417651,  0.15449726,  0.08654117,\n",
      "        0.13491473,  0.96092217,  0.32578698,  0.49476873,  0.11035416,\n",
      "        0.32354298,  0.14895715,  0.66667247,  0.13201074,  0.39174533,\n",
      "        0.08109713, -0.04452743,  0.91433494,  0.28615805,  0.04585531,\n",
      "        0.25977152,  0.32997382,  0.00502511,  0.35552153,  0.65318429,\n",
      "        0.50331248,  0.62571804,  0.40997577,  0.04440708,  0.04865737,\n",
      "        0.76500189,  0.34727625,  0.59961813,  0.37323182,  0.94732021,\n",
      "        0.91169319,  0.1664476 , -0.01862036,  0.65640385,  0.80945149,\n",
      "        0.09367627, -0.23018472,  0.05927294,  0.03705192,  0.1487237 ,\n",
      "        0.69431434,  0.04026884,  0.14950113,  0.73251889,  0.48075249,\n",
      "        0.11503162,  0.75117233,  0.12621499,  0.28615805,  0.13301147,\n",
      "        1.01647619,  0.58862978,  0.19101584,  1.03123147,  0.28527085,\n",
      "        0.1598361 ,  0.30282665, -0.0346309 ,  0.08366634,  0.4379502 ,\n",
      "        0.12696024,  0.34638905,  0.13454929,  0.35283245,  0.44542882,\n",
      "        0.94225945,  0.08750791,  0.12520568,  0.51720615,  0.31860805,\n",
      "        0.57349986,  0.17954856,  0.83481096,  0.34638905,  0.26923216,\n",
      "        0.58393041,  0.62571804,  0.29082705,  0.12617063,  0.12317302,\n",
      "        0.45400988,  0.59968895,  0.74174191,  0.39609667,  0.12398656,\n",
      "        0.08343716,  0.51086081,  0.31552036,  0.05146996,  0.44696167,\n",
      "        0.55328999,  1.04504773,  1.00455009,  1.16930401,  0.63548278,\n",
      "        0.1664476 ,  0.03836231,  0.32236943,  0.42833469,  0.65640385,\n",
      "        0.25193365,  0.00319816,  0.07629658,  0.83861921,  0.99420553,\n",
      "        0.49656975,  0.10697351,  0.68318186,  0.46283879,  0.65640385,\n",
      "        0.78472808,  0.48855608,  0.28321637,  0.13228855,  0.480997  ,\n",
      "       -0.02969117,  0.09309221,  0.16035068,  0.1431675 ,  0.49479535,\n",
      "        0.10701456,  0.08256387,  0.12644418,  0.21948365,  0.69918168,\n",
      "        1.02406006,  1.07527374,  0.29419299,  0.60562665,  0.11533178,\n",
      "        0.53682253,  0.15928982]), array([ 1.13740168e+00,  4.31448398e-01,  9.86090322e-01,  6.63306866e-01,\n",
      "        7.79257449e-02,  1.53533087e-01,  8.30249218e-01,  8.74835806e-02,\n",
      "        6.47329539e-01,  1.02930560e+00,  1.06355425e+00,  2.50470198e-01,\n",
      "        9.86229620e-01,  1.04665830e+00,  1.10322044e+00,  7.26766075e-01,\n",
      "        9.88281063e-02,  1.14920836e-01,  6.09645528e-01,  7.50476844e-01,\n",
      "        9.15251065e-02,  1.00181327e+00,  9.17658115e-01,  1.38811350e-01,\n",
      "        1.05573864e-01,  8.28219538e-01,  7.56031395e-01, -2.85429574e-01,\n",
      "        1.00563027e+00, -1.25043461e-01,  7.09545531e-01,  5.25429269e-01,\n",
      "        1.07124977e+00,  5.75283300e-01,  3.23337953e-01,  4.58778769e-01,\n",
      "        8.76487017e-02,  9.57370993e-01,  8.73662709e-02,  4.13720334e-01,\n",
      "        9.71039310e-01, -1.57324593e-02,  3.32036175e-01,  3.91306697e-01,\n",
      "        9.73966691e-01,  2.66154035e-01,  2.86391307e-01,  2.12187976e-01,\n",
      "        7.90494619e-01,  6.82562501e-01,  5.41057582e-01,  2.13434390e-01,\n",
      "        4.97078039e-03,  1.33568100e-01,  4.34871833e-01,  1.65235854e-01,\n",
      "        7.66924317e-02,  1.26202931e-01,  1.00048523e-01,  9.89161781e-01,\n",
      "        6.96054016e-01,  6.63405157e-01,  6.63405157e-01, -5.76872343e-02,\n",
      "        2.60046603e-01,  5.15624902e-01,  5.09643511e-02,  1.21937528e-01,\n",
      "        8.48452906e-02,  7.47886993e-01,  6.23563681e-01,  6.63306866e-01,\n",
      "        1.03611542e+00,  4.71561518e-01,  1.15312912e-01,  1.59657232e-01,\n",
      "        6.02713318e-01,  6.14913497e-01,  9.57554485e-01,  6.36168905e-01,\n",
      "        6.06262628e-01,  1.89186873e-01,  1.59448022e-01,  1.03506356e+00,\n",
      "        8.03198456e-01,  7.18672911e-02,  8.59496200e-01,  8.73662709e-02,\n",
      "        3.79637791e-01,  4.06595182e-02,  7.09545531e-01,  1.65933487e-01,\n",
      "        8.76301137e-01,  3.86686287e-01,  1.45972332e-01, -9.65077443e-04,\n",
      "        1.02640804e+00,  6.09428096e-01,  1.39226574e-01,  5.75916742e-01,\n",
      "        1.54620326e-01,  2.97980913e-01,  7.63245323e-01,  2.46469895e-02,\n",
      "        1.12436931e-01,  5.94965929e-01,  5.49716711e-02,  6.50734998e-01,\n",
      "        1.81857898e-01, -5.64352325e-02,  3.79045406e-01,  1.45956508e-01,\n",
      "        4.38148772e-01,  8.73662709e-02,  1.65270938e-01,  9.80590681e-01,\n",
      "        2.44802276e-01, -9.08179732e-03,  5.84841136e-01,  6.77744978e-01,\n",
      "        8.10530656e-01,  2.52662520e-01,  7.09536386e-01,  1.26713251e-01,\n",
      "        2.24618743e-01,  9.20665251e-02,  5.41006865e-01,  1.15528821e-01,\n",
      "        8.68749700e-02,  7.23493814e-01,  8.34113330e-01,  1.65949311e-01,\n",
      "        7.19623866e-02,  4.39905218e-01,  5.41057582e-01,  6.29053211e-01,\n",
      "        1.72445041e-01,  2.63919261e-01,  1.03245050e+00,  5.43296462e-01,\n",
      "        6.64395849e-01,  2.86155732e-01,  2.44014854e-01,  5.98786876e-01,\n",
      "        1.54014582e-01,  6.90657792e-02,  7.63511590e-01,  8.75311284e-02,\n",
      "        6.23441415e-01,  8.59423658e-01,  3.99430674e-01,  6.89294582e-01,\n",
      "        2.81012057e-01,  1.53063029e-01,  4.66416702e-02,  4.66673599e-01,\n",
      "        3.35272537e-01,  8.74835806e-02,  1.31429329e-01,  1.90312196e-01,\n",
      "        8.95150061e-01,  6.13203019e-01,  1.65949311e-01,  3.04990071e-01,\n",
      "        5.84708718e-02,  3.20826950e-01,  1.31238887e-01,  8.74835806e-02,\n",
      "        3.07270790e-02,  2.44802276e-01,  2.51024012e-01,  1.65930292e-01,\n",
      "        7.17964051e-01,  8.68749700e-02,  3.19538099e-02,  6.70657856e-01,\n",
      "        8.37189653e-01,  6.38137380e-01,  4.47804810e-01,  1.81857898e-01,\n",
      "        4.15280011e-02,  1.39017364e-01,  7.64697144e-01, -1.33065408e-02,\n",
      "        2.44802276e-01, -4.94612461e-02,  3.61371137e-01,  4.98673221e-01,\n",
      "        4.38148772e-01,  8.88405207e-01,  2.79275882e-01,  8.54539013e-02,\n",
      "        1.72959846e-01,  4.66416702e-02,  1.45557107e-01,  2.60774785e-01,\n",
      "        2.06647345e-01,  1.46165718e-01,  1.31705760e-01,  7.90656532e-01,\n",
      "        9.28469622e-02,  9.82249257e-01,  1.25735059e-01,  1.73614715e-01,\n",
      "        7.21989003e-01,  6.63214966e-01,  5.36760828e-01,  1.06381962e+00,\n",
      "        5.59450934e-01,  7.19234219e-01,  4.28443383e-01,  1.09957465e-01,\n",
      "        1.49292720e-01,  1.70665389e-01,  8.74835806e-02,  3.85739459e-01,\n",
      "        7.76303438e-01,  1.25506830e-01,  3.17419339e-01,  7.21135137e-01,\n",
      "        1.78425830e-01,  6.69527755e-01,  7.18450768e-02,  9.74704365e-01,\n",
      "        1.39302651e-01,  1.26202931e-01,  8.82368565e-01,  1.26206126e-01,\n",
      "        9.30891794e-02,  6.13203019e-01,  5.76966602e-01,  2.46469895e-02,\n",
      "        1.88707025e-01,  8.88664252e-01,  1.26206126e-01,  1.51744339e-01,\n",
      "        6.14634838e-01,  5.83277424e-01,  8.94814101e-01,  3.25227343e-01,\n",
      "        1.02388421e+00,  9.23905042e-02,  1.01410531e+00,  8.96674138e-01,\n",
      "        5.22071786e-01,  5.08580271e-01,  1.99153230e-01,  3.41703809e-01,\n",
      "        1.96639533e-01,  7.84205631e-01,  2.94695338e-01,  1.45801991e-02,\n",
      "        3.59010359e-01,  5.97174705e-01,  2.82789716e-01,  1.66009564e-01,\n",
      "        1.78139310e-01,  6.36568305e-01,  2.10549468e-01,  8.01714868e-01,\n",
      "        6.20684776e-01,  8.43329023e-01,  4.99542350e-01,  1.65949311e-01,\n",
      "        1.78790179e-02,  2.66534417e-01,  8.74835806e-02,  5.84841136e-01,\n",
      "        3.83613373e-02,  1.59539923e-01,  5.58589141e-01,  1.26206126e-01,\n",
      "        7.18134291e-02,  3.48963759e-02,  6.87768663e-01,  3.85815535e-01,\n",
      "        6.63306866e-01,  1.79894504e-01,  1.64564156e-01,  7.23037046e-01,\n",
      "        8.35480147e-01,  5.79155616e-01,  7.18672911e-02,  7.36554886e-01,\n",
      "        9.06437153e-01,  1.00654267e-01,  4.35613502e-01,  1.27334566e-01,\n",
      "        1.02467837e+00,  1.39506171e-01,  2.43315200e-01,  1.39419960e-01,\n",
      "        8.74835806e-02,  5.10214083e-02,  8.04148047e-01, -2.98325847e-02,\n",
      "        6.42868359e-01]), array([ 1.73847751e-01,  1.75641833e-02,  7.74555652e-01, -8.22856282e-03,\n",
      "        1.41669357e-01,  3.12421833e-01,  7.29144286e-01,  9.42072486e-02,\n",
      "        4.16776071e-01,  1.62859980e-02,  4.40486014e-01,  1.57178390e-02,\n",
      "        9.25689227e-02,  4.35480223e-01,  8.28706672e-01,  8.44995456e-01,\n",
      "        5.39507208e-01,  9.44920674e-02,  6.66224016e-01,  1.88728785e-01,\n",
      "        6.52916400e-02,  7.62693476e-01,  3.17375880e-02,  5.91691489e-01,\n",
      "        8.34004775e-01,  2.80566224e-01,  1.12328706e-01,  3.04774371e-01,\n",
      "        1.54752996e-01,  1.41588573e-01,  1.38811843e-01,  2.49734652e-01,\n",
      "        2.05618474e-01,  9.73877460e-01,  1.14349208e-01,  1.88734409e-01,\n",
      "        1.47059814e-01, -2.14941708e-02,  4.55491086e-01,  4.31054052e-01,\n",
      "        6.06562525e-01,  7.90542366e-01,  8.16689471e-02,  2.11176342e-01,\n",
      "        5.67387343e-01,  4.98413833e-02,  1.47033645e-01,  1.00769410e+00,\n",
      "        6.44678025e-01,  7.78414501e-02,  7.38491425e-01,  3.11199357e-01,\n",
      "        1.52464707e-01,  3.23125649e-01,  9.43236949e-02,  6.52509015e-01,\n",
      "        9.42072486e-02,  8.46367980e-01,  1.41393564e-01,  7.10410262e-01,\n",
      "        7.74476207e-01,  1.87035156e-01,  9.42072486e-02,  6.58437897e-01,\n",
      "        2.96059576e-01,  2.95529878e-01,  1.92302066e-01,  8.55803175e-02,\n",
      "        3.28233055e-01,  6.00331926e-02,  1.05406660e-01,  1.43474585e-01,\n",
      "        2.85169433e-01,  9.42479274e-02,  2.17310693e-02,  8.93648324e-01,\n",
      "        6.79585350e-01,  3.64856780e-01,  4.09830852e-02,  2.52499005e-01,\n",
      "        2.63960085e-01,  1.57950457e-01,  1.22464889e-01,  6.78962653e-01,\n",
      "        5.17207634e-01,  2.76199661e-01,  7.10306443e-01,  4.67148998e-01,\n",
      "        1.46572035e-01, -3.19754162e-02,  4.89757773e-02,  2.90663311e-01,\n",
      "        7.31414959e-03,  1.51698613e-01,  1.57943453e-01,  9.66375483e-01,\n",
      "        3.63173056e-01,  8.05968359e-01,  7.78414501e-02,  1.67256387e-01,\n",
      "        2.57123011e-01,  1.37984135e-01,  1.62859980e-02,  7.10442555e-01,\n",
      "        2.98995419e-01,  2.73108386e-02,  9.45479938e-01,  3.93338189e-01,\n",
      "        7.29387987e-01,  2.14318611e-01,  7.27600732e-02,  2.04560752e-01,\n",
      "        6.97807780e-01,  3.55222690e-01,  9.43650765e-01,  1.02107600e-01,\n",
      "        1.01436024e+00,  4.22113477e-01,  2.72290567e-01,  9.74794116e-02,\n",
      "        1.38152507e-01,  1.52547479e-01,  8.78181655e-01,  7.96829299e-01,\n",
      "        1.86119013e-01,  7.62743875e-02,  9.08341388e-01,  1.22035111e-01,\n",
      "        2.36163791e-01,  1.49042650e-01,  3.86266646e-01,  1.46761454e-01,\n",
      "        6.52148834e-01,  7.10441141e-01,  2.39188607e-01,  5.99889449e-01,\n",
      "        8.85402134e-01,  2.39593774e-01,  2.63960085e-01,  2.96059576e-01,\n",
      "        2.96059576e-01,  9.79738078e-02,  4.79972957e-01,  2.76902382e-01,\n",
      "        9.42072486e-02,  9.42072486e-02,  4.20951707e-01,  3.28589825e-01,\n",
      "        8.85290723e-01,  8.08734854e-02,  8.71140184e-02,  1.50843196e-01,\n",
      "        1.27778915e-01,  7.79652223e-01,  4.29827217e-01,  1.81645388e-01,\n",
      "        8.80995836e-01,  2.26450963e-01,  7.56935027e-02,  1.30684422e-01,\n",
      "        6.32011764e-01,  3.80282108e-01,  1.03492740e-01,  3.23790050e-01,\n",
      "        7.07367113e-02,  9.05660231e-01,  9.19833184e-02,  3.29327010e-02,\n",
      "        1.94480330e-01,  8.45925621e-01,  1.68840600e-01,  7.68922177e-01,\n",
      "        4.64955176e-01,  7.06076070e-01,  1.41603027e-01,  8.15216212e-02,\n",
      "        1.24699145e-01, -5.42835269e-03,  6.33477159e-01,  1.41669357e-01,\n",
      "        6.18226968e-01,  1.57958876e-01,  1.88728785e-01,  7.48861831e-01,\n",
      "        1.88732995e-01,  8.13913485e-01,  7.54303976e-01,  9.61112201e-01,\n",
      "        4.24758452e-01,  5.68510083e-02,  1.20079098e-01,  1.20011749e-01,\n",
      "        6.79752623e-01,  1.38013884e-01,  2.14087892e-01,  3.62860614e-01,\n",
      "        1.88728785e-01,  3.29797392e-01,  2.71813214e-01,  4.67953619e-01,\n",
      "        1.19794279e-01,  2.08938434e-01,  8.38935993e-01,  6.08566811e-01,\n",
      "        1.40029616e-01,  5.71942758e-01,  2.36163791e-01,  7.32884489e-01,\n",
      "        4.60344258e-01,  3.05403617e-01,  1.09214211e-01,  8.71645302e-02,\n",
      "        3.80410084e-01,  6.79658604e-01,  2.08938434e-01,  8.75304365e-01,\n",
      "        1.14352003e-01,  3.80897630e-02,  2.31560582e-01,  5.80158082e-01,\n",
      "        8.97944610e-02,  4.31054052e-01,  6.52382736e-01,  2.54791141e-01,\n",
      "        2.22698611e-02,  7.94093077e-02,  7.62985868e-01,  1.08645954e-01,\n",
      "        3.85855155e-01,  6.33812611e-01,  7.26550056e-02,  1.88998181e-01,\n",
      "        7.78414501e-02,  4.64488774e-01,  1.88728785e-01,  7.49942004e-01,\n",
      "        6.99377708e-01,  3.77979731e-01,  1.41667942e-01,  1.30698431e-01,\n",
      "        1.57773666e-01,  8.84490529e-01,  1.41316382e-01,  9.41553225e-02,\n",
      "        6.53129816e-02,  4.68288950e-01,  1.47009803e-01,  3.35016937e-01,\n",
      "        9.87921002e-01,  1.15793396e-01,  1.63096668e-01,  2.73445131e-02,\n",
      "       -2.49894932e-01,  1.12579786e-01,  2.66841672e-01,  9.28389896e-01,\n",
      "        6.93400785e-02, -1.46973537e-01,  7.36523919e-01,  1.01882947e+00,\n",
      "        6.57440398e-01,  6.83870581e-01,  7.77069001e-01,  3.06128653e-01,\n",
      "        7.04584503e-01,  1.41667942e-01, -5.26251760e-02,  2.65851692e-01,\n",
      "        8.44381064e-01,  2.71813214e-01,  2.90614504e-01,  7.14311367e-01,\n",
      "        8.01331485e-01,  4.06966455e-01,  9.36670425e-02,  1.96189772e-01,\n",
      "        1.14349208e-01,  8.03999511e-01,  4.11396788e-01, -3.69123579e-04,\n",
      "        7.92471249e-01,  7.43415247e-01,  1.46362984e-01,  1.52464707e-01,\n",
      "        9.42072486e-02,  8.33527460e-01,  8.07242247e-01,  7.62337087e-02,\n",
      "        6.56955065e-01,  2.69676081e-01,  1.20079098e-01,  6.76306792e-01,\n",
      "        2.74279290e-01,  1.00091731e+00,  5.78559155e-01,  4.88329886e-01,\n",
      "        1.76200317e-01])]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7856341189674523\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays. Concatenate them into one.\n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0.)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <= .5] = 0\n",
    "accuracy = sum(predictions == titanic['Survived'])/len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7901234567901234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zoe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\zoe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\zoe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "alg = LogisticRegression(random_state=1)\n",
    "scores = cross_val_score(alg,titanic[predictors], titanic['Survived'], cv=3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7946127946127947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "kf = KFold( n_splits=3, random_state=1)\n",
    "scores = cross_val_score(alg,titanic[predictors], titanic['Survived'], cv=kf)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327721661054994\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=4, min_samples_leaf=2)\n",
    "kf = KFold( n_splits=3, random_state=1)\n",
    "scores = cross_val_score(alg,titanic[predictors], titanic['Survived'], cv=kf)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327721661054994\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=4, min_samples_leaf=2)\n",
    "kf = KFold( n_splits=3, random_state=1)\n",
    "scores = cross_val_score(alg,titanic[predictors], titanic['Survived'], cv=kf)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a famiysize column\n",
    "titanic['FamilySize'] = titanic['SibSp'] + titanic['Parch']\n",
    "\n",
    "# The .apply method generate a new series\n",
    "titanic['NameLength'] = titanic['Name'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Major         2\n",
      "Mlle          2\n",
      "Col           2\n",
      "Sir           1\n",
      "Lady          1\n",
      "Mme           1\n",
      "Don           1\n",
      "Jonkheer      1\n",
      "Countess      1\n",
      "Ms            1\n",
      "Capt          1\n",
      "Name: Name, dtype: int64\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# A function to get a title from name\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title. Titles always consist of capital and lowercase letters\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs\n",
    "titles = titanic['Name'].apply(get_title)\n",
    "print(pd.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer. Some titles are very rare, and are compressed into the same codes as other \n",
    "title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6, 'Major': 7, 'Mlle': 8, 'Col':7, 'Mme': 8, 'Don': 9, 'Lady':10, 'Countess': 10, 'Jonkheer': 10, 'Sir': 9, 'Capt':7, 'Ms':2 }\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything\n",
    "print(pd.value_counts(titles))\n",
    "\n",
    "# Add in the title column\n",
    "titanic['Title'] = titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819304152637486\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "predictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize', 'NameLength']\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic['Survived'])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores. See how 'Pclass', 'Sex', 'Title', and 'Fare' are best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Pick only the four best features\n",
    "predictors = ['Pclass', 'Sex', 'Fare','Title']\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=8, min_samples_leaf=4)\n",
    "kf = KFold( n_splits=3, random_state=1)\n",
    "scores = cross_val_score(alg,titanic[predictors], titanic['Survived'], cv=kf)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8215488215488216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zoe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\zoe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\zoe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# The algorithm we want to ensemble\n",
    "# We are using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3),['Pclass', 'Sex', 'Fare', 'FamilySize', 'Title', 'Age', 'Embarked'] ],\n",
    "    [LogisticRegression(random_state=1),['Pclass', 'Sex', 'Fare', 'FamilySize', 'Title', 'Age', 'Embarked'] ]\n",
    "]\n",
    "\n",
    "kf = KFold( n_splits=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf.split(titanic):\n",
    "    train_target = titanic['Survived'].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold\n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembing schame -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0]*4 + full_test_predictions[1])/5\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and blow .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "    \n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "accuracy = sum(predictions == titanic['Survived'])/len(predictions)\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
